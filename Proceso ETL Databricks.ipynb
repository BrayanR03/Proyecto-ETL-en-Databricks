{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8f0dd3f-1e6a-49aa-a5fa-ac1957950690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PROYECTO ETL EN DATABRICKS - COSMETSAC\n",
    "Autor: Brayan R. Neciosup Bolaños\n",
    "\n",
    "Importante:\n",
    "Como no se tiene desplegada una BD relacional en la nube, usaremos Unity Catalog \n",
    "y todas sus características para simular una BD relacional en Databricks. \n",
    "\n",
    "El Modelo Entidad Relación esta elaborado en MSSM, puedes visualizarlo en la imagen denominada: \n",
    "ModeloER-SQL.png \n",
    "en la carpeta database_loca O también puedes revisar el script: ScriptBDCosmetSAC.sql en la misma carpeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f1ec660-fe12-4c41-9625-40b19d9dc2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LIBRERÍAS UTILIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247ceb94-795f-4518-9bfa-f43c9619f1ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Librerias a utilizar\n",
    "from pyspark.sql import SparkSession # Puerta de acceso a todas las funcionalidades de apache spark\n",
    "from pyspark.sql.functions import * # Funciones SQL\n",
    "from pyspark.sql.types import * # Funciones de tipos de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "732d1566-7465-4826-a593-dd6d737c9759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CONFIGURACIONES Y FUNCIONES UTILIZADAS PARA LA CARGA DE INFORMACIÓN EN UNITY CATALOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea377e1b-5b91-479d-8105-1347a4826849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Configuración de Unity Catalog para simular BD relacional\n",
    "# A). Creación del Catálago (Nivel más alto en la jerarquía de Unity Catalog) \n",
    "# [Es como crear la BD en cualquier gestor de BD]\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS cosmetsac\")\n",
    "print(\"Catálago creado exitosamente\")\n",
    "\n",
    "# B). Creación del Esquema (Segundo nivel en la jerarquía de Unity Catalog) \n",
    "# [Son como los esquemas dentro de cualquier gestor de BD] \n",
    "# [En caso no creamos conveniente crearlo, podemos usar el esquema \"default\"]\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS cosmetsac.ventas\") # Permite administrar mejor cada entidad\n",
    "print(\"Esquema ventas creado exitosamente\")\n",
    "\n",
    "# Importante: No crearemos los volumenes, porque las tablas donde se almacenarán los datos\n",
    "#             serán entidades gobernada por Unity Catalog y permitirá usar el lenguaje SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adcefee9-4eeb-4e99-b6ad-50654ae5a664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información a la tabla de clientes \n",
    "def cargar_informacion_clientes_cosmetsac(dataframe_clientes):\n",
    "    # dataframe_clientes.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernado por Unity Catalog\n",
    "    dataframe_clientes.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.clientes\")\n",
    "    print(\"Datos de clientes registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.clientes\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8765aff6-aa23-45a6-98da-f0cc4ca2455a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información de tablas externas (Marcas,Categorias,FormasPagos)\n",
    "# La similitud de estas 3 tablas, se debe a su estructura en sus campos.\n",
    "def cargar_datos_tablas_externas(nombre_tabla,dataframe_tabla_externa):\n",
    "    # dataframe_tabla_externa.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernada por Unity Catalog\n",
    "    jerarquia_unity_catalog_tabla = f\"cosmetsac.ventas.{nombre_tabla}\" # Formateamos la jerarquia en base al nombre de la tabla\n",
    "    dataframe_tabla_externa.write.format(\"delta\").mode(\"overwrite\").saveAsTable(jerarquia_unity_catalog_tabla)\n",
    "    print(f\"Datos de {nombre_tabla} registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(jerarquia_unity_catalog_tabla): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023c5725-0111-4315-916a-69625ff3f6b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información a la tabla productos\n",
    "def cargar_datos_productos(dataframe_productos):\n",
    "    # dataframe_productos.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gorbernada por Unity Catalog\n",
    "    dataframe_productos.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.productos\")\n",
    "    print(\"Datos de productos registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.productos\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f4252c-1846-4651-959c-949132189870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Funciión encargada de cargar la información a la tabla productos\n",
    "def cargar_datos_pedidos(dataframe_pedidos):\n",
    "    # dataframe_pedidos.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernada por Unity Catalog\n",
    "    dataframe_pedidos.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.pedidos\")\n",
    "    print(\"Datos de pedidos registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.productos\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a48542-4644-4416-ba67-e95e00292f7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Funciión encargada de cargar la información a la tabla promociones\n",
    "def cargar_datos_promociones(dataframe_promociones):\n",
    "    # dataframe_pedidos.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernada por Unity Catalog\n",
    "    dataframe_promociones.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.promociones\")\n",
    "    print(\"Datos de promociones registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.productos\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698de7ef-5fcd-4af9-9471-af3a3d26d025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función que permite traer los ID Compra por cada Cliente (ID Cliente)\n",
    "def cargar_pedidos_ids_clientes(dataframe_clientes_ids):\n",
    "    # Inicializamos un datafame con datos en 0, que se llenará dinamicamente más adelante.\n",
    "    df_pedidos_clientes = spark.createDataFrame(schema=[\"PedidosClientesID\",\"PedidosID\"],data=[(0,0)]) \n",
    "    for i in dataframe_clientes_ids.select(col(\"PedidosClientesID\")).collect(): # Recorremos cada ID de cliente\n",
    "        # Retornamos un dataframe con los todos los pedidos (PedidosID) de cada cliente iterado del dataframe.\n",
    "        df_ids_pedidos = spark.sql(f\"SELECT PedidosID FROM cosmetsac.ventas.pedidos WHERE PedidosClientesID = {i[0]}\")\n",
    "        # print(f\"CANTIDAD DE PEDIDOS DEL CLIENTE: {i[0]} es: {df_ids_pedidos.count()}\") # Verificamos la cantidad de pedidos por cliente\n",
    "        if df_ids_pedidos.count()>0: # Validamos que el dataframe anterior contenga información.\n",
    "            # Creamos un diccionario que almacenará el ClienteID y sus respectivos PedidosID, esto permitirá crear un dataframe mas rápido\n",
    "            diccionario_compras_clientes = {\n",
    "                \"PedidosClientesID\": [i[0] for _ in range(1,df_ids_pedidos.count()+1)],\n",
    "                \"PedidosID\": [i[0] for i in df_ids_pedidos.select(col(\"PedidosID\")).collect()]\n",
    "            }\n",
    "            # print(diccionario_compras_clientes) # Verificamos la información del diccionario\n",
    "            # Creamos un dataframe temporal que será llenado con la información del diccionario creado anteriormente.\n",
    "            df_temp = spark.createDataFrame(data=list(zip(*diccionario_compras_clientes.values())),schema=[\"PedidosClientesID\",\"PedidosID\"])\n",
    "            # .union() permite unir la información por filas entre dataframes, en este caso, \n",
    "            # el dataframe inicializado con datos en 0 y llenado dinamicamente con el dataframe temporal (df_temp)\n",
    "            df_pedidos_clientes = df_pedidos_clientes.union(df_temp) # Llenado dinámico por cada dataframe del diccionario\n",
    "        else:\n",
    "            print(\"Dataframe sin datos\")\n",
    "    df_pedidos_clientes = df_pedidos_clientes.filter(\n",
    "        (col(\"PedidosClientesID\")!=0) & (col(\"PedidosID\")!=0) \n",
    "        # Filtramos todos los datos diferentes de 0 del dataframe inicial que ha sido llenado dinámicamente\n",
    "    )\n",
    "    return df_pedidos_clientes # Retornamos el dataframe con los valores correctos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de83fcb-1f5a-4668-93ac-f1c3a73caf9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Funciión encargada de preparar un dataframe con la estructura de la tabla detallepedidos.\n",
    "def preparar_tabla_detalle_pedidos(df_clientes_pedidos_ids,df_ventas_f):\n",
    "    df_detalle_pedidos = df_ventas_f.select( # Seleccionamos las columnas necesarias del dataframe de ventas\n",
    "        col(\"ID Cliente\").alias(\"PedidosClientesID\"), # Renombramos la columna ID Cliente a PedidosClientesID para facilitar el .join()\n",
    "        col(\"ID Producto\"),col(\"Cantidad\"),col(\"Precio Unitario (S/)\"),col(\"Promocion ID\")\n",
    "    )\n",
    "    # Mediante .join() realizamos la unión de los dataframes (df_clientes_pedidos_ids y df_ventas_f) de manera columnar.\n",
    "    df_detalle_pedidos = df_detalle_pedidos.join(df_clientes_pedidos_ids,how=\"inner\",on=\"PedidosClientesID\")\n",
    "    return df_detalle_pedidos.sort(col(\"PedidosID\").asc()) # Retornamos el dataframe df_detalle_pedidos ordenados por PedidosID (ascendente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ac119b-d019-4805-b33f-5b4ffe9ca7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información a la tabla de detalle pedidos\n",
    "def cargar_datos_detalle_pedidos(dataframe):\n",
    "    # Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "    dataframe = dataframe.select(\n",
    "        col(\"PedidosID\").alias(\"DetallePedidosPedidoID\"),\n",
    "        col(\"ID Producto\").alias(\"DetallePedidosProductoID\"),\n",
    "        col(\"Precio Unitario (S/)\").alias(\"DetallePedidosPrecioVenta\"),\n",
    "        col(\"Cantidad\").alias(\"DetallePedidosCantidad\"),\n",
    "        col(\"Promocion ID\").alias(\"DetallePedidosPromocionID\")\n",
    "    )\n",
    "    # dataframe.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernada por Unity Catalog\n",
    "    dataframe.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.detallepedidos\")\n",
    "    print(\"Datos de Detalle Pedidos registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.productos\"): Permite guardarse como delta table optimizada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6b4d83-7c38-4d2b-9a79-706e30251330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PROCESO ETL (EXTRAER - TRANSFORMAR Y CARGAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2008cff-e0b7-4486-8c68-cf56ca4c2d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### INCONSISTENCIAS POR SUBSANAR EN LOS ARCHIVOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f29c9cc6-ae87-4da7-ad15-7804057bf0d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Estas son las inconsistencias encontradas en los archivos : \n",
    "CLIENTES-EMPRESA-COSMETSAC.csv | PRODUCTOS-EMPRESA-COSMETSAC.csv | VENTAS-EMPRESA-COSMETSAC.csv\n",
    "\n",
    "Archivo CLIENTES-EMPRESA-COSMETSAC.csv: \n",
    "\n",
    "- Los nombres y apellidos de los clientes presentan guiones(-) entre sus registros.\n",
    "- Los nombres y apellidos de los clientes se encuentran en una sola columna.\n",
    "- El teléfono de los clientes presentan el prefijo \"51\".\n",
    "- Los clientes no tienen un ID asignado.\n",
    "\n",
    "ARCHIVO PRODUCTOS-EMPRESA-COSMETSAC.csv:\n",
    "\n",
    "- Las categorias y marcas no tienen un ID asignado.\n",
    "- Los ID de cada producto tienen un prefijo \"P\" y tienen ceros inicialmente.\n",
    "   (Se omite esta columna en el ETL y se asigna automáticamente)\n",
    "\n",
    "ARCHIVO VENTAS-EMPRESA-COSMETSAC.csv:\n",
    "\n",
    "- Las ventas registradas no tiene un ID asignado (Incoherencia fuerte).\n",
    "- El ID de cada cliente tiene un prefijo de C junto con ceros inicialmente.\n",
    "- Redudancia de información con columnas que deberían estar presentes en otras tablas.\n",
    "- La columna Promoción tiene sus campos propios, pero no un ID asignado correctamente.\n",
    "- La columna PagosDescripcion tiene su campo propio, pero no un ID asignado correctamente.\n",
    "\n",
    " SOLUCIÓN: CREAR UNA BD RELACIONAL SIMULADA EN DATABRICKS UTILIZANDO UNITY CATALOG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "267908db-fca9-490f-97b2-f1897c2c3a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### CÓDIGO ETL - EMPRESA COSMET S.A.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cfe0121-4a9f-4bac-b680-3d43269d89fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo CLIENTES-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(clientes_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "clientes_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.clientes_empresa_cosmetsac\")\n",
    "# clientes_cosmetsac.show() # Leemos las 5 primeras filas de la tabla\n",
    "\n",
    "#### Transformar\n",
    "#-- Limpiar la columna CLIENTE de guiones que existen\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"CLIENTE\": regexp_replace(col(\"CLIENTE\"),r'-',' '), # Función que permite reemplazar (-) por espacios en blanco.\n",
    "    \"TELEFONO\": cast(StringType(),col(\"TELEFONO\")) # Convertimos a String el Telefono para poder extraer el prefijo 51\n",
    "})\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"CLIENTE\":upper(col(\"CLIENTE\")), # La información de los nombres y apellidos del clientes, lo convertimos a mayúsculas\n",
    "    \"TELEFONO\":cast(IntegerType(),regexp_replace(col(\"TELEFONO\"),r'^51','')) \n",
    "    # Reemplazamos el prefijo \"51\" por un espacio en blanco y convertimos a tipo IntegerType() para manetener la integridad de datos.\n",
    "})\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"Primer Nombre Cliente\":split(col(\"CLIENTE\"),\" \").getItem(0), # .split() Permite separar la información\n",
    "    \"Segundo Nombre Cliente\":split(col(\"CLIENTE\"),\" \").getItem(1),# basandose en un delimitador, para poder convertirlo a un array\n",
    "    \"Primer Apellido Cliente\":split(col(\"CLIENTE\"),\" \").getItem(2), # mismo array, al cu+al accedemos a cada elemtno respectivamente\n",
    "    \"Segundo Apellido Cliente\":split(col(\"CLIENTE\"),\" \").getItem(3) # con .getItem(IndiceElemento)\n",
    "})\n",
    "\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"Apellidos\":concat_ws(', ',col(\"Primer Apellido Cliente\"),col(\"Segundo Apellido Cliente\")), # Concatemos el primer y segundo apellido\n",
    "    \"Nombres\":concat_ws(', ',col(\"Primer Nombre Cliente\"),col(\"Segundo Nombre Cliente\")) # Concatemos el primer y segundo nombre\n",
    "    # Ambas concatenaciones las volvemos en una sola columna respectivamente\n",
    "})\n",
    "\n",
    "clientes_cosmetsac = clientes_cosmetsac.select(\n",
    "    col(\"Apellidos\"),col(\"Nombres\"),col(\"DNI\"),col(\"CORREO ELECTRONICO\"),col(\"TELEFONO\") \n",
    "    # Seleccionamos en orden las columnas de acuerdo a la estructura de la tabla clientes\n",
    ")\n",
    "\n",
    "# clientes_cosmetsac.show()\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "clientes_bd = clientes_cosmetsac.withColumn(\n",
    "    \"ClientesID\",                  # Agrego una columna para el ID del cliente\n",
    "    monotonically_increasing_id()+1 # Columna con datos autoincrementables empezando en 1\n",
    ")\n",
    "clientes_bd = clientes_bd.select( # Modificamos el nombre de ciertas columnas en base a la tabla clientes\n",
    "    col(\"ClientesID\"),col(\"Apellidos\").alias(\"ClientesApellidos\"),\n",
    "    col(\"Nombres\").alias(\"ClientesNombres\"),col(\"DNI\").alias(\"ClientesDNI\"),\n",
    "    col(\"CORREO ELECTRONICO\").alias(\"ClientesCorreoElectronico\"),col(\"TELEFONO\").alias(\"ClientesTelefono\")\n",
    ")\n",
    "# clientes_bd.show()\n",
    "\n",
    "#### CARGAR\n",
    "# FUNCIÓN PARA CONVERTIR ESTE DATAFRAME A UN DELTA TABLE EN UNITY CATALOG\n",
    "cargar_informacion_clientes_cosmetsac(clientes_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bb15a33-a8aa-4cb0-9e35-42fa703978d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo PRODUCTOS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(productos_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "\n",
    "productos_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.productos_empresa_cosmetsac\")\n",
    "# productos_cosmetsac.show() \n",
    "\n",
    "#### TRANSFORMAR\n",
    "\n",
    "productos_cosmetsac = productos_cosmetsac.select( # Seleccionamos las columnas específicas en base a la estructura de la tabla Productos\n",
    "    col(\"Producto\"),col(\"Precio regular (S/)\"),col(\"Stock Actualizado\"),\n",
    "    col(\"Marca\"),col(\"Categoría\")\n",
    ")\n",
    "productos_cosmetsac = productos_cosmetsac.withColumnsRenamed({\n",
    "    \"Precio regular (S/)\":\"Precio Compra\", # Renombramos la columna Precio Regular (S/) a Precio Compra\n",
    "    \"Stock Actualizado\":\"Stock\" # Renombramos la columna Stock Actualizado a Stock\n",
    "})\n",
    "\n",
    "# EXTRAEMOS LAS MARCAS\n",
    "marcas_unicas = productos_cosmetsac.select(col(\"Marca\")).dropDuplicates() # Eliminamos duplicados\n",
    "diccionario_marcas = {\n",
    "    # Permite crear un ID por cada marca única existente\n",
    "    \"Marca ID\":[i for i in range(1,marcas_unicas.count()+1)],\n",
    "    # Retorna cada marca única existente.\n",
    "    \"Marca\":[i[0] for i in marcas_unicas.select(col(\"Marca\")).collect()]\n",
    "}\n",
    "df_marcas = spark.createDataFrame(list(zip(*diccionario_marcas.values())),[\"Marca ID\",\"Marca\"])\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "marcas_bd = df_marcas.select(col(\"Marca ID\").alias(\"MarcasID\"),col(\"Marca\").alias(\"MarcasDescripcion\"))\n",
    "# df_marcas.show()\n",
    "\n",
    "# EXTRAEMOS LAS CATEGORIAS\n",
    "\n",
    "categorias_unicas = productos_cosmetsac.select(col(\"Categoría\")).dropDuplicates() # Eliminamos duplicados\n",
    "diccionario_categorias = {\n",
    "    # Permite crear un ID por cada categoría única existente\n",
    "    \"Categoria ID\":[i for i in range(1,categorias_unicas.count()+1)],\n",
    "    # Retorna cada categoría única existente\n",
    "    \"Categoría\": [i[0] for i in categorias_unicas.select(col(\"Categoría\")).collect()]\n",
    "}\n",
    "df_categorias = spark.createDataFrame(list(zip(*diccionario_categorias.values())),[\"Categoria ID\",\"Categoría\"])\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "categorias_bd = df_categorias.select(col(\"Categoria ID\").alias(\"CategoriasID\"),col(\"Categoría\").alias(\"CategoriasDescripcion\"))\n",
    "# df_categorias.show()\n",
    "\n",
    "# Accedemos a los dataframes anteriores y con .join() unificamos la información a nivel de columna\n",
    "# Es como realizar un INNER JOIN de 2 tablas en SQL SERVER, permitiendo tener el ID de la Marca y Categoria\n",
    "# respectivamente donde aparece en la información.\n",
    "productos_cosmetsac = productos_cosmetsac.join(df_marcas,\"Marca\")\n",
    "productos_cosmetsac = productos_cosmetsac.join(df_categorias,\"Categoría\")\n",
    "\n",
    "# Seleccionamos columnas necesarias.\n",
    "productos_cosmetsac = productos_cosmetsac.select(\n",
    "    col(\"Producto\"),col(\"Precio Compra\"),col(\"Stock\"),\n",
    "    col(\"Marca ID\"),col(\"Categoria ID\")\n",
    ")\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "productos_bd = productos_cosmetsac.withColumn(\n",
    "    \"ProductosID\",                  # # Agrego una columna para el ID del producto\n",
    "    monotonically_increasing_id()+1 # Columna con datos autoincrementables empezando en 1\n",
    ")\n",
    "productos_bd = productos_bd.select(\n",
    "    col(\"ProductosID\"),col(\"Producto\").alias(\"ProductosDescripcion\"),\n",
    "    col(\"Precio Compra\").alias(\"ProductosPrecioCompra\"),col(\"Stock\").alias(\"ProductosStock\"),\n",
    "    col(\"Marca ID\").alias(\"ProductosMarcasID\"),col(\"Categoria ID\").alias(\"ProductosCategoriasID\")\n",
    ")\n",
    "# productos_bd.show()\n",
    "\n",
    "#### CARGAR\n",
    "\n",
    "# Funciones para cargar información ....\n",
    "cargar_datos_tablas_externas(nombre_tabla=\"marcas\",dataframe_tabla_externa=marcas_bd) # Tabla marcas\n",
    "cargar_datos_tablas_externas(nombre_tabla=\"categorias\",dataframe_tabla_externa=categorias_bd) # Tabla categorias\n",
    "cargar_datos_productos(productos_bd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f4fd2d-4769-4df1-8f7c-859789021cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo VENTAS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(ventas_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "\n",
    "ventas_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.ventas_empresa_cosmetsac\")\n",
    "# ventas_cosmetsac.show()\n",
    "\n",
    "#### TRANSFORMAR\n",
    "\n",
    "# # Extraemos las formas de pago\n",
    "formas_pago_unicas = ventas_cosmetsac.select(col(\"PagosDescripcion\")).dropDuplicates()\n",
    "diccionario_formas_pago = {\n",
    "    # Permite crear un ID por cada forma de pago única existente\n",
    "    \"FormaPagoID\":[i for i in range(1,formas_pago_unicas.count()+1)],\n",
    "    # Retorna cada descripción de las formas de pago únicas existentes\n",
    "    \"PagosDescripcion\":[i[0] for i in formas_pago_unicas.select(col(\"PagosDescripcion\")).collect()]\n",
    "}\n",
    "df_formas_pago = spark.createDataFrame(data=list(zip(*diccionario_formas_pago.values())),schema=[\"FormaPagoID\",\"PagosDescripcion\"])\n",
    "# df_formas_pago.show()\n",
    "\n",
    "# Extraemos las promociones\n",
    "promociones_unicas = ventas_cosmetsac.select(\n",
    "    col(\"Promocion\"),col(\"FechaInicio\"),col(\"FechaFin\")\n",
    ").dropDuplicates()\n",
    "\n",
    "# Agregamos columna Descuento de la descripción\n",
    "promociones_unicas = promociones_unicas.withColumns({\n",
    "    \"Promocion ID\":                   # Agregamos una columna para el Promocion ID\n",
    "    monotonically_increasing_id()+1,  # Columna con datos autoincrementables empezando en 1\n",
    "    \"Descuento\":\n",
    "    (regexp_extract(col(\"Promocion\"),r'\\d+',0)/100),\n",
    "    \"Estado\":\n",
    "    lit(0)\n",
    "})\n",
    "# promociones_unicas.show()\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "promociones_bd = promociones_unicas.select(\n",
    "    col(\"Promocion ID\").alias(\"PromocionesID\"),\n",
    "    col(\"Promocion\").alias(\"PromocionesDescripcion\"),\n",
    "    col(\"Descuento\").alias(\"PromocionesDescuento\"),\n",
    "    col(\"FechaInicio\").alias(\"PromocionesFechaInicio\"),\n",
    "    col(\"FechaFin\").alias(\"PromocionesFechaFin\"),\n",
    "    col(\"Estado\").alias(\"PromocionesEstado\")\n",
    ")\n",
    "promociones_bd = promociones_bd.withColumn(\n",
    "    \"PromocionesEstado\",\n",
    "    when(\n",
    "        # Mantendremos siempre activa la promoción con 0% (Regla de negocio)\n",
    "        col(\"PromocionesDescripcion\")=='Sin Promoción: 0% de Descuento',lit(1) \n",
    "    ).otherwise(lit(0))\n",
    ")\n",
    "# promociones_bd.show()\n",
    "\n",
    "# Construimos el dataframe ventas final para la fase de Carga\n",
    "# 1️⃣ Unimos con el dataframe de Formas Pagos\n",
    "df_ventas_cosmetsac = ventas_cosmetsac.join(df_formas_pago,on=\"PagosDescripcion\",how=\"inner\")\n",
    "# 2️⃣ Unimos con el dataframe de Promociones\n",
    "df_ventas_cosmetsac = df_ventas_cosmetsac.join(promociones_unicas,how=\"inner\",on=\"Promocion\")\n",
    "# 3️⃣ Estandarizamos el ID Cliente e ID Producto\n",
    "df_ventas_cosmetsac = df_ventas_cosmetsac.withColumns({\n",
    "    \"ID Cliente\":\n",
    "    regexp_replace(col(\"ID Cliente\"),r'^C','').cast(dataType=IntegerType()),\n",
    "    \"ID Producto\":\n",
    "    regexp_replace(col(\"ID Producto\"),r'^P','').cast(dataType=IntegerType())\n",
    "})\n",
    "# df_ventas_cosmetsac.show() \n",
    "\n",
    "# Seleccionamos columnas necesarias para poblar la tabla Pedidos en la fase de Carga\n",
    "df_pedidos = df_ventas_cosmetsac.select(col(\"FechaCompra\"),col(\"ID Cliente\"),col(\"FormaPagoID\")).sort(col(\"FechaCompra\").asc())\n",
    "# df_pedidos.show()\n",
    "\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "formas_pagos_bd = df_formas_pago.select(\n",
    "    col(\"FormaPagoID\").alias(\"FormasPagosID\"),\n",
    "    col(\"PagosDescripcion\").alias(\"FormasPagosDescripcion\")\n",
    ")\n",
    "# formas_pagos_bd.show()\n",
    "pedidos_bd = df_pedidos.withColumn(\n",
    "    \"PedidosID\",                    # Agrego una columna para el ID de pedidos\n",
    "    monotonically_increasing_id()+1 # Columna con datos autoincrementables empezando en 1\n",
    ")\n",
    "pedidos_bd = pedidos_bd.select(\n",
    "    col(\"PedidosID\"),col(\"FechaCompra\").alias(\"PedidosFechaRegistro\"),\n",
    "    col(\"ID Cliente\").alias(\"PedidosClientesID\"),col(\"FormaPagoID\").alias(\"PedidosFormasPagosID\")\n",
    ")\n",
    "# pedidos_bd.show()\n",
    "\n",
    "### CARGAR\n",
    "# Funciones para cargar las tablas formas de pago, promociones y pedidos\n",
    "cargar_datos_promociones(dataframe_promociones=promociones_bd)\n",
    "cargar_datos_tablas_externas(nombre_tabla=\"formaspagos\",dataframe_tabla_externa=formas_pagos_bd)\n",
    "cargar_datos_pedidos(dataframe_pedidos=pedidos_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6eeb13-4e68-47fe-a7c6-4a588a74589f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo VENTAS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(ventas_empresa_cosmetsac)\n",
    "# ETL ➡️ Tabla DetallePedidos\n",
    "\n",
    "#### EXTRAER Y TRANSFORMAR\n",
    "# Extraer los IDs de los clientes que tienen un pedido registrado\n",
    "\n",
    "clientes_ids = pedidos_bd.select(col(\"PedidosClientesID\")).dropDuplicates().sort(col(\"PedidosClientesID\").asc())\n",
    "# clientes_ids = clientes_ids.filter((col(\"PedidosClientesID\")==1) | (col(\"PedidosClientesID\")==2) | (col(\"PedidosClientesID\")==3))\n",
    "# clientes_ids.show()\n",
    "\n",
    "#### CARGAR\n",
    "# Función que permite extraer todos los IDs de Pedidos de los clientes\n",
    "clientes_ids_pedidos = cargar_pedidos_ids_clientes(dataframe_clientes_ids=clientes_ids)\n",
    "# Función que prepara el dataframe de la función anterior, para el poblado de la tabla DetallePedidos\n",
    "df_detalle_pedidos = preparar_tabla_detalle_pedidos(df_clientes_pedidos_ids=clientes_ids_pedidos,df_ventas_f=df_ventas_cosmetsac)\n",
    "# Función que permite realizar la carga de información a la tabla DetallePedidos\n",
    "cargar_datos_detalle_pedidos(df_detalle_pedidos) \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Proceso ETL Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

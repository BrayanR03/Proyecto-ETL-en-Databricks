{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8f0dd3f-1e6a-49aa-a5fa-ac1957950690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PROYECTO ETL EN DATABRICKS - COSMETSAC\n",
    "Autor: Brayan R. Neciosup Bolaños\n",
    "\n",
    "Importante:\n",
    "Como no se tiene desplegada una BD relacional en la nube, usaremos Unity Catalog \n",
    "y todas sus características para simular una BD relacional en Databricks. \n",
    "\n",
    "El Modelo Entidad Relación esta elaborado en MSSM, puedes visualizarlo en la imagen denominada: ModeloER-SQL.png\n",
    "O también puedes revisar el script: ScriptBDCosmetSAC.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f1ec660-fe12-4c41-9625-40b19d9dc2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LIBRERÍAS UTILIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247ceb94-795f-4518-9bfa-f43c9619f1ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Librerias a utilizar\n",
    "from pyspark.sql import SparkSession # Puerta de acceso a todas las funcionalidades de apache spark\n",
    "from pyspark.sql.functions import * # Funciones SQL\n",
    "from pyspark.sql.types import * # Funciones de tipos de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "732d1566-7465-4826-a593-dd6d737c9759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CONFIGURACIONES Y FUNCIONES UTILIZADAS PARA LA CARGA DE INFORMACIÓN EN UNITY CATALOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea377e1b-5b91-479d-8105-1347a4826849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Configuración de Unity Catalog para simular BD relacional\n",
    "# A). Creación del Catálago (Nivel más alto en la jerarquía de Unity Catalog) \n",
    "# [Es como crear la BD en cualquier gestor de BD]\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS cosmetsac\")\n",
    "print(\"Catálago creado exitosamente\")\n",
    "\n",
    "# B). Creación del Esquema (Segundo nivel en la jerarquía de Unity Catalog) \n",
    "# [Son como los esquemas dentro de cualquier gestor de BD] \n",
    "# [En caso no creamos conveniente crearlo, podemos usar el esquema \"default\"]\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS cosmetsac.ventas\") # Permite administrar mejor cada entidad\n",
    "print(\"Esquema ventas creado exitosamente\")\n",
    "\n",
    "# Importante: No crearemos los volumenes, porque las tablas donde se almacenarán los datos\n",
    "#             serán entidades gobernada por Unity Catalog y permitirá usar el lenguaje SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adcefee9-4eeb-4e99-b6ad-50654ae5a664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información a la tabla de clientes \n",
    "def cargar_informacion_clientes_cosmetsac(dataframe_clientes):\n",
    "    # dataframe_clientes.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernado por Unity Catalog\n",
    "    dataframe_clientes.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.clientes\")\n",
    "    print(\"Datos de clientes registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.clientes\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8765aff6-aa23-45a6-98da-f0cc4ca2455a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información de tablas externas (Marcas,Categorias,FormasPagos)\n",
    "# La similitud de estas 3 tablas, se debe a su estructura en sus campos.\n",
    "def cargar_datos_tablas_externas(nombre_tabla,dataframe_tabla_externa):\n",
    "    # dataframe_tabla_externa.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gobernada por Unity Catalog\n",
    "    jerarquia_unity_catalog_tabla = f\"cosmetsac.ventas.{nombre_tabla}\" # Formateamos la jerarquia en base al nombre de la tabla\n",
    "    dataframe_tabla_externa.write.format(\"delta\").mode(\"overwrite\").saveAsTable(jerarquia_unity_catalog_tabla)\n",
    "    print(f\"Datos de {nombre_tabla} registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(jerarquia_unity_catalog_tabla): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023c5725-0111-4315-916a-69625ff3f6b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función encargada de cargar la información a la tabla productos\n",
    "def cargar_datos_productos(dataframe_productos):\n",
    "    # dataframe_productos.show()\n",
    "    # Almacenaremos el dataframe en una delta table que será gorbernada por Unity Catalog\n",
    "    dataframe_productos.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cosmetsac.ventas.productos\")\n",
    "    print(\"Datos de productos registrados\")\n",
    "    # write: Modo de escritura\n",
    "    # format(\"delta\"): Es la forma nativa de Databricks para almacenar información (Optimizada y recomendada)\n",
    "    # mode(\"overwrite\"): Sobreescribe toda la información existente sin perder nada de datos.\n",
    "    # saveAsTable(\"cosmetsac.ventas.productos\"): Permite guardarse como delta table optimizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6b4d83-7c38-4d2b-9a79-706e30251330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PROCESO ETL (EXTRAER - TRANSFORMAR Y CARGAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cfe0121-4a9f-4bac-b680-3d43269d89fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo CLIENTES-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(clientes_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "clientes_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.clientes_empresa_cosmetsac\")\n",
    "# clientes_cosmetsac.show() # Leemos las 5 primeras filas de la tabla\n",
    "\n",
    "#### Transformar\n",
    "#-- Limpiar la columna CLIENTE de guiones que existen\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"CLIENTE\": regexp_replace(col(\"CLIENTE\"),r'-',' '),\n",
    "    \"TELEFONO\": cast(StringType(),col(\"TELEFONO\"))\n",
    "})\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"CLIENTE\":upper(col(\"CLIENTE\")),\n",
    "    \"TELEFONO\":cast(IntegerType(),regexp_replace(col(\"TELEFONO\"),r'^51',''))\n",
    "})\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"Primer Nombre Cliente\":split(col(\"CLIENTE\"),\" \").getItem(0), # .split() Permite separar la información\n",
    "    \"Segundo Nombre Cliente\":split(col(\"CLIENTE\"),\" \").getItem(1),# basandose en un delimitador, para poder convertirlo a un array\n",
    "    \"Primer Apellido Cliente\":split(col(\"CLIENTE\"),\" \").getItem(2), # mismo array, al cu+al accedemos a cada elemtno respectivamente\n",
    "    \"Segundo Apellido Cliente\":split(col(\"CLIENTE\"),\" \").getItem(3) # con .getItem(IndiceElemento)\n",
    "})\n",
    "\n",
    "clientes_cosmetsac = clientes_cosmetsac.withColumns({\n",
    "    \"Apellidos\":concat_ws(', ',col(\"Primer Apellido Cliente\"),col(\"Segundo Apellido Cliente\")),\n",
    "    \"Nombres\":concat_ws(', ',col(\"Primer Nombre Cliente\"),col(\"Segundo Nombre Cliente\"))\n",
    "})\n",
    "\n",
    "clientes_cosmetsac = clientes_cosmetsac.select(\n",
    "    col(\"Apellidos\"),col(\"Nombres\"),col(\"DNI\"),col(\"CORREO ELECTRONICO\"),col(\"TELEFONO\")\n",
    ")\n",
    "\n",
    "# clientes_cosmetsac.show()\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "clientes_bd = clientes_cosmetsac.withColumn(\n",
    "    \"ClientesID\",                  # Agrego una columna para el ID del cliente\n",
    "    monotonically_increasing_id()+1\n",
    ")\n",
    "clientes_bd = clientes_bd.select(\n",
    "    col(\"ClientesID\"),col(\"Apellidos\").alias(\"ClientesApellidos\"),\n",
    "    col(\"Nombres\").alias(\"ClientesNombres\"),col(\"DNI\").alias(\"ClientesDNI\"),\n",
    "    col(\"CORREO ELECTRONICO\").alias(\"ClientesCorreoElectronico\"),col(\"TELEFONO\").alias(\"ClientesTelefono\")\n",
    ")\n",
    "# clientes_bd.show()\n",
    "\n",
    "#### CARGAR\n",
    "# FUNCIÓN PARA CONVERTIR ESTE DATAFRAME A UN DELTA TABLE EN UNITY CATALOG\n",
    "cargar_informacion_clientes_cosmetsac(clientes_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bb15a33-a8aa-4cb0-9e35-42fa703978d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo PRODUCTOS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(productos_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "\n",
    "productos_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.productos_empresa_cosmetsac\")\n",
    "# productos_cosmetsac.show() \n",
    "\n",
    "#### TRANSFORMAR\n",
    "\n",
    "productos_cosmetsac = productos_cosmetsac.select(\n",
    "    col(\"Producto\"),col(\"Precio regular (S/)\"),col(\"Stock Actualizado\"),\n",
    "    col(\"Marca\"),col(\"Categoría\")\n",
    ")\n",
    "productos_cosmetsac = productos_cosmetsac.withColumnsRenamed({\n",
    "    \"Precio regular (S/)\":\"Precio Compra\",\n",
    "    \"Stock Actualizado\":\"Stock\"\n",
    "})\n",
    "\n",
    "# EXTRAEMOS LAS MARCAS\n",
    "marcas_unicas = productos_cosmetsac.select(col(\"Marca\")).dropDuplicates() # Eliminamos duplicados\n",
    "diccionario_marcas = {\n",
    "    \"Marca ID\":[i for i in range(1,marcas_unicas.count()+1)],\n",
    "    \"Marca\":[i[0] for i in marcas_unicas.select(col(\"Marca\")).collect()]\n",
    "}\n",
    "df_marcas = spark.createDataFrame(list(zip(*diccionario_marcas.values())),[\"Marca ID\",\"Marca\"])\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "marcas_bd = df_marcas.select(col(\"Marca ID\").alias(\"MarcasID\"),col(\"Marca\").alias(\"MarcasDescripcion\"))\n",
    "# df_marcas.show()\n",
    "\n",
    "# EXTRAEMOS LAS CATEGORIAS\n",
    "\n",
    "categorias_unicas = productos_cosmetsac.select(col(\"Categoría\")).dropDuplicates()\n",
    "diccionario_categorias = {\n",
    "    \"Categoria ID\":[i for i in range(1,categorias_unicas.count()+1)],\n",
    "    \"Categoría\": [i[0] for i in categorias_unicas.select(col(\"Categoría\")).collect()]\n",
    "}\n",
    "df_categorias = spark.createDataFrame(list(zip(*diccionario_categorias.values())),[\"Categoria ID\",\"Categoría\"])\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "categorias_bd = df_categorias.select(col(\"Categoria ID\").alias(\"CategoriasID\"),col(\"Categoría\").alias(\"CategoriasDescripcion\"))\n",
    "# df_categorias.show()\n",
    "\n",
    "productos_cosmetsac = productos_cosmetsac.join(df_marcas,\"Marca\")\n",
    "productos_cosmetsac = productos_cosmetsac.join(df_categorias,\"Categoría\")\n",
    "\n",
    "# Seleccionamos columnas necesarias.\n",
    "productos_cosmetsac = productos_cosmetsac.select(\n",
    "    col(\"Producto\"),col(\"Precio Compra\"),col(\"Stock\"),\n",
    "    col(\"Marca ID\"),col(\"Categoria ID\")\n",
    ")\n",
    "# Preparamos dataframe para una correcta coherencia con la estructura definida de la tabla:\n",
    "productos_bd = productos_cosmetsac.withColumn(\n",
    "    \"ProductosID\",\n",
    "    monotonically_increasing_id()+1\n",
    ")\n",
    "productos_bd = productos_bd.select(\n",
    "    col(\"ProductosID\"),col(\"Producto\").alias(\"ProductosDescripcion\"),\n",
    "    col(\"Precio Compra\").alias(\"ProductosPrecioCompra\"),col(\"Stock\").alias(\"ProductosStock\"),\n",
    "    col(\"Marca ID\").alias(\"ProductosMarcasID\"),col(\"Categoria ID\").alias(\"ProductosCategoriasID\")\n",
    ")\n",
    "# productos_bd.show()\n",
    "\n",
    "#### CARGAR\n",
    "\n",
    "# Funciones para cargar información ....\n",
    "cargar_datos_tablas_externas(nombre_tabla=\"marcas\",dataframe_tabla_externa=marcas_bd) # Tabla marcas\n",
    "cargar_datos_tablas_externas(nombre_tabla=\"categorias\",dataframe_tabla_externa=categorias_bd) # Tabla categorias\n",
    "cargar_datos_productos(productos_bd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f4fd2d-4769-4df1-8f7c-859789021cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo VENTAS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(ventas_empresa_cosmetsac)\n",
    "\n",
    "#### EXTRAER\n",
    "\n",
    "ventas_cosmetsac = spark.sql(\"SELECT * FROM workspace.exercises.ventas_empresa_cosmetsac\")\n",
    "# ventas_cosmetsac.show()\n",
    "\n",
    "#### TRANSFORMAR\n",
    "\n",
    "# Extraemos las formas de pago\n",
    "formas_pago_unicas = ventas_cosmetsac.select(col(\"PagosDescripcion\")).dropDuplicates()\n",
    "diccionario_formas_pago = {\n",
    "    \"FormaPagoID\":[i for i in range(1,formas_pago_unicas.count()+1)],\n",
    "    \"PagosDescripcion\":[i[0] for i in formas_pago_unicas.select(col(\"PagosDescripcion\")).collect()]\n",
    "}\n",
    "df_formas_pago = spark.createDataFrame(data=list(zip(*diccionario_formas_pago.values())),schema=[\"FormaPagoID\",\"PagosDescripcion\"])\n",
    "# df_formas_pago.show()\n",
    "\n",
    "# Extraemos las promociones\n",
    "promociones_unicas = ventas_cosmetsac.select(\n",
    "    col(\"Promocion\"),col(\"FechaInicio\"),col(\"FechaFin\")\n",
    ").dropDuplicates()\n",
    "\n",
    "# Agregamos columna Descuento de la descripción\n",
    "promociones_unicas = promociones_unicas.withColumns({\n",
    "    \"Promocion ID\":\n",
    "    monotonically_increasing_id()+1,    \n",
    "    \"Descuento\":\n",
    "    (regexp_extract(col(\"Promocion\"),r'\\d+',0)/100),\n",
    "    \"Estado\":\n",
    "    lit(0)\n",
    "})\n",
    "# promociones_unicas.show()\n",
    "\n",
    "# Construimos el dataframe ventas final para la fase de Carga\n",
    "# 1️⃣ Unimos con el dataframe de Formas Pagos\n",
    "df_ventas_cosmetsac = ventas_cosmetsac.join(df_formas_pago,on=\"PagosDescripcion\",how=\"inner\")\n",
    "# 2️⃣ Unimos con el dataframe de Promociones\n",
    "df_ventas_cosmetsac = df_ventas_cosmetsac.join(promociones_unicas,how=\"inner\",on=\"Promocion\")\n",
    "# 3️⃣ Estandarizamos el ID Cliente e ID Producto\n",
    "df_ventas_cosmetsac = df_ventas_cosmetsac.withColumns({\n",
    "    \"ID Cliente\":\n",
    "    regexp_replace(col(\"ID Cliente\"),r'^C','').cast(dataType=IntegerType()),\n",
    "    \"ID Producto\":\n",
    "    regexp_replace(col(\"ID Producto\"),r'^P','').cast(dataType=IntegerType())\n",
    "})\n",
    "# df_ventas_cosmetsac.show() \n",
    "\n",
    "# Seleccionamos columnas necesarias para poblar la tabla Pedidos en la fase de Carga\n",
    "df_pedidos = df_ventas_cosmetsac.select(col(\"FechaCompra\"),col(\"ID Cliente\"),col(\"FormaPagoID\")).sort(col(\"FechaCompra\").asc())\n",
    "# df_pedidos.show()\n",
    "\n",
    "#### CARGAR\n",
    "# Funciones para cargar las tablas formas de pago, promociones y pedidos .....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6eeb13-4e68-47fe-a7c6-4a588a74589f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Archivo VENTAS-EMPRESA-COSMETSAC.xlsx cargada previamente a Unity Catalog en formato delta table(ventas_empresa_cosmetsac)\n",
    "# ETL ➡️ Tabla DetallePedidos\n",
    "\n",
    "#### EXTRAER Y TRANSFORMAR\n",
    "# Extraer los IDs de los clientes que tienen un pedido registrado\n",
    "\n",
    "clientes_ids = df_pedidos.select(col(\"ID Cliente\")).dropDuplicates()\n",
    "# clientes_ids.show()\n",
    "\n",
    "#### CARGAR\n",
    "# Función que permite extraer todos los IDs de Pedidos de los clientes\n",
    "# ....\n",
    "\n",
    "# Función que prepara el dataframe de la función anterior, para el poblado de la tabla DetallePedidos\n",
    "# ....\n",
    "\n",
    "# Función que permite realizar la carga de información a la tabla DetallePedidos\n",
    "# .... \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37abc05f-5857-4df6-a688-ec5579048ea2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Proceso ETL Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
